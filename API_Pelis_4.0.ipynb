{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # Importa BeautifulSoup \n",
    "import pandas as pd  # Importa la biblioteca pandas y la renombra como pd\n",
    "import requests  # Importa la biblioteca requests\n",
    "import re  # Importa la biblioteca re\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Configura pandas para mostrar todas las columnas de un DataFrame al imprimir\n",
    "\n",
    "url = \"https://moviesdatabase.p.rapidapi.com/titles\"  # ENDPOINT\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"b0262d2945msh1f1577867db30c6p12fca9jsnc5eb4666d6bb\",  # Clave de API para autenticación\n",
    "    \"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"  # Host de la API \n",
    "}\n",
    "\n",
    "def llamar_pelis(url, headers, year):  # Define una función llamada llamar_pelis \n",
    "    datos_paginas = []  # Inicializa una lista vacía para almacenar datos\n",
    "    base_url = \"https://moviesdatabase.p.rapidapi.com\"  # URL base para la API\n",
    "    querystring = {\"genre\": \"Drama\", \"startYear\": year, \"titleType\": \"movie\", \"endYear\": year}  # Parámetros de la consulta\n",
    "    while url:  # Un bucle while que se ejecuta mientras url no esté vacía\n",
    "        if not url.startswith('http'):  # Verifica si la url no comienza con 'http'\n",
    "            url = base_url + url  # Prepara la url completa añadiendo base_url si es necesario\n",
    "        response = requests.get(url, headers=headers, params=querystring)  # Realiza una solicitud GET a la API\n",
    "        if response.status_code == 200:  # Comprueba si el estado de la respuesta es 200 (éxito)\n",
    "            json_pelis = response.json()  # Convierte la respuesta en JSON\n",
    "            datos_paginas.extend(json_pelis['results'])  # Agrega los resultados al listado de datos_paginas\n",
    "            url = json_pelis.get('next')  # Actualiza la url con el valor de 'next' si existe, para itinerar por páginas\n",
    "            querystring = {}  # Limpia los parámetros de la consulta para la siguiente solicitud\n",
    "        else:\n",
    "            print(\"Error en la solicitud:\", response.status_code, response.reason)  # Imprime un mensaje de error si falla la solicitud\n",
    "            return None  # Termina la función retornando None debido a error\n",
    "    return {\"results\": datos_paginas}  # Devuelve un diccionario con los datos recopilados\n",
    "\n",
    "def limpiar_json(datos_json):  # Define una función para procesar y limpiar los datos JSON\n",
    "    peliculas = []  # Crea una lista vacía para almacenar datos de películas\n",
    "    for pelicula in datos_json['results']:  # Itera sobre cada película en los resultados\n",
    "        tipo = pelicula['titleType']['text']  # Extrae el tipo de título de la películ\n",
    "        nombre = pelicula['titleText']['text']  # Extrae el nombre de la película\n",
    "        year = pelicula['releaseYear']['year']  # Extrae el año de lanzamiento de la película\n",
    "        mes = pelicula['releaseDate']['month'] if 'releaseDate' in pelicula and pelicula['releaseDate'] is not None else 'No consta'  # Extrae el mes de lanzamiento o asigna 'No consta'.\n",
    "        peliculas.append({\n",
    "            'Tipo': tipo,  # Añade el tipo al diccionario\n",
    "            'Nombre': nombre,  # Añade el nombre al diccionario\n",
    "            'Año de Estreno': year,  # Añade el año de estreno al diccionario\n",
    "            'Mes de Estreno': mes,  # Añade el mes de estreno al diccionario\n",
    "            'ID': id_pelicula  # Añade el ID al diccionario\n",
    "        })\n",
    "    return pd.DataFrame(peliculas)  # Retorna un DataFrame de pandas con los datos de películas\n",
    "\n",
    "# Proceso iterativo sobre el rango de años\n",
    "todos_los_datos = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2010, 2025):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        todos_los_datos.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final = pd.concat(todos_los_datos, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final.head(50))  # Imprime los primeros 50 registros del DataFrame final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final = pd.concat(todos_los_datos, ignore_index=True)\n",
    "print(df_final.head (50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_csv(\"Peliculas_Head.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
