{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # Importa BeautifulSoup \n",
    "import pandas as pd  # Importa la biblioteca pandas y la renombra como pd\n",
    "import requests  # Importa la biblioteca requests\n",
    "import re  # Importa la biblioteca re\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Configura pandas para mostrar todas las columnas de un DataFrame al imprimir\n",
    "\n",
    "url = \"https://moviesdatabase.p.rapidapi.com/titles\"  # ENDPOINT\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"431e779057msh1f0c87c2937a329p125efcjsn45064e4b4925\",  # Clave de API para autenticación\n",
    "    \"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"  # Host de la API \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def llamar_pelis(url, headers, year):  # Define una función llamada llamar_pelis \n",
    "    datos_paginas = []  # Inicializa una lista vacía para almacenar datos\n",
    "    base_url = \"https://moviesdatabase.p.rapidapi.com\"  # URL base para la API\n",
    "    querystring = {\"genre\": \"Drama\", \"startYear\": year, \"titleType\": \"movie\", \"endYear\": year}  # Parámetros de la consulta\n",
    "    while url:  # Un bucle while que se ejecuta mientras url no esté vacía\n",
    "        if not url.startswith('http'):  # Verifica si la url no comienza con 'http'\n",
    "            url = base_url + url  # Prepara la url completa añadiendo base_url si es necesario\n",
    "        response = requests.get(url, headers=headers, params=querystring)  # Realiza una solicitud GET a la API\n",
    "        if response.status_code == 200:  # Comprueba si el estado de la respuesta es 200 (éxito)\n",
    "            json_pelis = response.json()  # Convierte la respuesta en JSON\n",
    "            datos_paginas.extend(json_pelis['results'])  # Agrega los resultados al listado de datos_paginas\n",
    "            url = json_pelis.get('next')  # Actualiza la url con el valor de 'next' si existe, para itinerar por páginas\n",
    "            querystring = {}  # Limpia los parámetros de la consulta para la siguiente solicitud\n",
    "        else:\n",
    "            print(\"Error en la solicitud:\", response.status_code, response.reason)  # Imprime un mensaje de error si falla la solicitud\n",
    "            return None  # Termina la función retornando None debido a error\n",
    "    return {\"results\": datos_paginas}  # Devuelve un diccionario con los datos recopilados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_json(datos_json):  # Define una función para procesar y limpiar los datos JSON\n",
    "    peliculas = []  # Crea una lista vacía para almacenar datos de películas\n",
    "    for pelicula in datos_json['results']:  # Itera sobre cada película en los resultados\n",
    "        tipo = pelicula['titleType']['text']  # Extrae el tipo de título de la películ\n",
    "        nombre = pelicula['titleText']['text']  # Extrae el nombre de la película\n",
    "        year = pelicula['releaseYear']['year']  # Extrae el año de lanzamiento de la película\n",
    "        mes = pelicula['releaseDate']['month'] if 'releaseDate' in pelicula and pelicula['releaseDate'] is not None else 'No consta'  # Extrae el mes de lanzamiento o asigna 'No consta'.\n",
    "        id_pelicula = pelicula['id']\n",
    "        \n",
    "        peliculas.append({\n",
    "            'Tipo': tipo,  # Añade el tipo al diccionario\n",
    "            'Nombre': nombre,  # Añade el nombre al diccionario\n",
    "            'Año de Estreno': year,  # Añade el año de estreno al diccionario\n",
    "            'Mes de Estreno': mes,  # Añade el mes de estreno al diccionario\n",
    "            'ID': id_pelicula  # Añade el ID al diccionario\n",
    "        })\n",
    "    return pd.DataFrame(peliculas)  # Retorna un DataFrame de pandas con los datos de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Tipo                    Nombre  Año de Estreno Mes de Estreno  \\\n",
      "0     Movie               Pál Adrienn            2010              6   \n",
      "1     Movie            Oda az igazság            2010              2   \n",
      "2     Movie  A zöld sárkány gyermekei            2010              4   \n",
      "3     Movie         The Final Journey            2010              9   \n",
      "4     Movie               In My Sleep            2010              4   \n",
      "...     ...                       ...             ...            ...   \n",
      "9731  Movie                     Think            2011              2   \n",
      "9732  Movie                       831            2011             11   \n",
      "9733  Movie            Charkh o Falak            2011      No consta   \n",
      "9734  Movie    The Life of a Stranger            2011              6   \n",
      "9735  Movie           Ljubav, oziljci            2011           None   \n",
      "\n",
      "              ID  \n",
      "0      tt0146592  \n",
      "1      tt0154039  \n",
      "2      tt0162942  \n",
      "3      tt0230212  \n",
      "4      tt0326965  \n",
      "...          ...  \n",
      "9731  tt32109328  \n",
      "9732  tt32133624  \n",
      "9733  tt32200284  \n",
      "9734  tt32251702  \n",
      "9735  tt32254251  \n",
      "\n",
      "[9736 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata0 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2010, 2012):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata0.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final0 = pd.concat(alldata0, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final0)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final0.to_csv(\"Películas_Comedia_2010-2011.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en la solicitud: 429 Too Many Requests\n",
      "Error en la solicitud: 429 Too Many Requests\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1066/3119154704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Concatena todos los DataFrames anuales en uno solo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_final1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Usa concatenación para unir todos los DataFrames y reindexa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Imprime los primeros 50 registros del DataFrame final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata1 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2011, 2013):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata1.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final1 = pd.concat(alldata1, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final1)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1.to_csv(\"Películas_Comedia_2011-2012.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata2 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2012, 2014):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata2.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final2 = pd.concat(alldata2, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final2)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.to_csv(\"Películas_Comedia_2012-2013.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata3 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2013, 2015):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata3.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final3 = pd.concat(alldata3, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final3)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3.to_csv(\"Películas_Comedia_2013-2014.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata4 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2014, 2016):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata4.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final4 = pd.concat(alldata4, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final4)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final4.to_csv(\"Películas_Comedia_2014-2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata5 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2015, 2017):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata5.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final5 = pd.concat(alldata5, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final5)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final5.to_csv(\"Películas_Comedia_2015-2016.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata6 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2016, 2018):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata6.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final6 = pd.concat(alldata6, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final6)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final6.to_csv(\"Películas_Comedia_2016-2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata7 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2017, 2019):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata7.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final7 = pd.concat(alldata7, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final7)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final7.to_csv(\"Películas_Comedia_2017-2018.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata8 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2018, 2020):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata8.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final8 = pd.concat(alldata8, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final8)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final8.to_csv(\"Películas_Comedia_2018-2019.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata9 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2019, 2021):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata9.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final9 = pd.concat(alldata9, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final9)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9.to_csv(\"Películas_Comedia_2019-2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata10 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2020, 2022):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata10.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final10 = pd.concat(alldata10, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final10)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final10.to_csv(\"Películas_Comedia_2020-2021.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata11 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2021, 2023):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata11.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final11 = pd.concat(alldata11, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final11)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final11.to_csv(\"Películas_Comedia_2021-2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata12 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2022, 2024):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata12.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final12 = pd.concat(alldata12, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final12)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final12.to_csv(\"Películas_Comedia_2022-2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata13 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2023, 2025):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata13.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final13 = pd.concat(alldata13, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final13)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final13.to_csv(\"Películas_Comedia_2023-2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata14 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2024, 2026):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata14.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final14 = pd.concat(alldata14, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final14)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final14.to_csv(\"Películas_Comedia_2024.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
