{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # Importa BeautifulSoup \n",
    "import pandas as pd  # Importa la biblioteca pandas y la renombra como pd\n",
    "import requests  # Importa la biblioteca requests\n",
    "import re  # Importa la biblioteca re\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Configura pandas para mostrar todas las columnas de un DataFrame al imprimir\n",
    "\n",
    "url = \"https://moviesdatabase.p.rapidapi.com/titles\"  # ENDPOINT\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"2a71737446mshd130aebe5b852b0p1d4674jsn1c93e1eccde5\",  # Clave de API para autenticación\n",
    "    \"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"  # Host de la API \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def llamar_pelis(url, headers, year):  # Define una función llamada llamar_pelis \n",
    "    datos_paginas = []  # Inicializa una lista vacía para almacenar datos\n",
    "    base_url = \"https://moviesdatabase.p.rapidapi.com\"  # URL base para la API\n",
    "    querystring = {\"genre\": \"Drama\", \"startYear\": year, \"titleType\": \"movie\", \"endYear\": year}  # Parámetros de la consulta\n",
    "    while url:  # Un bucle while que se ejecuta mientras url no esté vacía\n",
    "        if not url.startswith('http'):  # Verifica si la url no comienza con 'http'\n",
    "            url = base_url + url  # Prepara la url completa añadiendo base_url si es necesario\n",
    "        response = requests.get(url, headers=headers, params=querystring)  # Realiza una solicitud GET a la API\n",
    "        if response.status_code == 200:  # Comprueba si el estado de la respuesta es 200 (éxito)\n",
    "            json_pelis = response.json()  # Convierte la respuesta en JSON\n",
    "            datos_paginas.extend(json_pelis['results'])  # Agrega los resultados al listado de datos_paginas\n",
    "            url = json_pelis.get('next')  # Actualiza la url con el valor de 'next' si existe, para itinerar por páginas\n",
    "            querystring = {}  # Limpia los parámetros de la consulta para la siguiente solicitud\n",
    "        else:\n",
    "            print(\"Error en la solicitud:\", response.status_code, response.reason)  # Imprime un mensaje de error si falla la solicitud\n",
    "            return None  # Termina la función retornando None debido a error\n",
    "    return {\"results\": datos_paginas}  # Devuelve un diccionario con los datos recopilados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_json(datos_json):  # Define una función para procesar y limpiar los datos JSON\n",
    "    peliculas = []  # Crea una lista vacía para almacenar datos de películas\n",
    "    for pelicula in datos_json['results']:  # Itera sobre cada película en los resultados\n",
    "        tipo = pelicula['titleType']['text']  # Extrae el tipo de título de la películ\n",
    "        nombre = pelicula['titleText']['text']  # Extrae el nombre de la película\n",
    "        year = pelicula['releaseYear']['year']  # Extrae el año de lanzamiento de la película\n",
    "        mes = pelicula['releaseDate']['month'] if 'releaseDate' in pelicula and pelicula['releaseDate'] is not None else 'No consta'  # Extrae el mes de lanzamiento o asigna 'No consta'.\n",
    "        id_pelicula = pelicula['id']\n",
    "        \n",
    "        peliculas.append({\n",
    "            'Tipo': tipo,  # Añade el tipo al diccionario\n",
    "            'Nombre': nombre,  # Añade el nombre al diccionario\n",
    "            'Año de Estreno': year,  # Añade el año de estreno al diccionario\n",
    "            'Mes de Estreno': mes,  # Añade el mes de estreno al diccionario\n",
    "            'ID': id_pelicula  # Añade el ID al diccionario\n",
    "        })\n",
    "    return pd.DataFrame(peliculas)  # Retorna un DataFrame de pandas con los datos de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata0 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2010, 2012):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata0.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final0 = pd.concat(alldata0, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final0)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final0.to_csv(\"Películas_Comedia_2010-2011.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata1 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2011, 2013):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata1.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final1 = pd.concat(alldata1, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final1)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1.to_csv(\"Películas_Drama_2011-2012.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en la solicitud: 403 Forbidden\n",
      "Error en la solicitud: 429 Too Many Requests\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9438/3759539427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Concatena todos los DataFrames anuales en uno solo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_final2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Usa concatenación para unir todos los DataFrames y reindexa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Imprime los primeros 50 registros del DataFrame final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata2 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2012, 2014):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata2.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final2 = pd.concat(alldata2, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final2)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.to_csv(\"Películas_Drama_2012-2013.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata3 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2013, 2015):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata3.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final3 = pd.concat(alldata3, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final3)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3.to_csv(\"Películas_Comedia_2013-2014.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata4 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2014, 2016):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata4.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final4 = pd.concat(alldata4, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final4)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final4.to_csv(\"Películas_Comedia_2014-2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata5 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2015, 2017):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata5.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final5 = pd.concat(alldata5, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final5)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final5.to_csv(\"Películas_Comedia_2015-2016.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata6 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2016, 2018):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata6.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final6 = pd.concat(alldata6, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final6)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final6.to_csv(\"Películas_Comedia_2016-2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata7 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2017, 2019):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata7.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final7 = pd.concat(alldata7, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final7)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final7.to_csv(\"Películas_Comedia_2017-2018.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata8 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2018, 2020):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata8.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final8 = pd.concat(alldata8, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final8)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final8.to_csv(\"Películas_Comedia_2018-2019.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata9 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2019, 2021):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata9.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final9 = pd.concat(alldata9, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final9)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9.to_csv(\"Películas_Comedia_2019-2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata10 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2020, 2022):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata10.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final10 = pd.concat(alldata10, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final10)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final10.to_csv(\"Películas_Comedia_2020-2021.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata11 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2021, 2023):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata11.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final11 = pd.concat(alldata11, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final11)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final11.to_csv(\"Películas_Comedia_2021-2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata12 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2022, 2024):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata12.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final12 = pd.concat(alldata12, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final12)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final12.to_csv(\"Películas_Comedia_2022-2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata13 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2023, 2025):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata13.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final13 = pd.concat(alldata13, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final13)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final13.to_csv(\"Películas_Comedia_2023-2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso iterativo sobre el rango de años\n",
    "alldata14 = []  # Crea una lista vacía para almacenar los DataFrames de cada año\n",
    "for year in range(2024, 2026):  # Itera sobre cada año desde 2010 hasta 2024\n",
    "    datos_anuales = llamar_pelis(url, headers, year)  # Llama a la función llamar_pelis para obtener datos del año\n",
    "    if datos_anuales:  # Si se recibieron datos exitosamente\n",
    "        df_anual = limpiar_json(datos_anuales)  # Llama a la función limpiar_json para procesar los datos\n",
    "        alldata14.append(df_anual)  # Añade el DataFrame al listado de todos los datos\n",
    "\n",
    "# Concatena todos los DataFrames anuales en uno solo\n",
    "df_final14 = pd.concat(alldata14, ignore_index=True)  # Usa concatenación para unir todos los DataFrames y reindexa\n",
    "print(df_final14)  # Imprime los primeros 50 registros del DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final14.to_csv(\"Películas_Comedia_2024.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
